# -*- coding: utf-8 -*-
"""cuda_grayscale_colab.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eeM26xZ24Tvt6e45T67Sq_CYFvuE97S7

# GPU vs CPU Performance Comparison: Image Grayscale Conversion

This notebook demonstrates the speed difference between CPU and GPU (CUDA) implementations for converting a color image to grayscale.

## 1. Setup and Verify CUDA Available
"""

!pip install numba-cuda==0.4.0 --force-reinstall

import torch
print("CUDA available:", torch.cuda.is_available())
print("GPU name:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "No GPU")

from numba import config
config.CUDA_ENABLE_PYNVJITLINK = 1

# Install required packages if they're not already installed
!pip install numba opencv-python matplotlib

import numpy as np
import cv2
import time
import matplotlib.pyplot as plt
from numba import cuda
import urllib.request
import os

# Check if CUDA is available through numba
print(f"CUDA available: {cuda.is_available()}")
if cuda.is_available():
    device = cuda.get_current_device()
    print(f"CUDA device: {device.name}")
    print(f"Compute capability: {device.compute_capability}")
    print(f"Max threads per block: {device.MAX_THREADS_PER_BLOCK}")
    print(f"Max shared memory per block: {device.MAX_SHARED_MEMORY_PER_BLOCK} bytes")

"""## 2. Download Test Images

Let's download some sample images of different sizes to test performance across various workloads.
"""

def download_image(url, filename):
    if not os.path.exists(filename):
        print(f"Downloading {filename}...")
        urllib.request.urlretrieve(url, filename)
    else:
        print(f"{filename} already exists.")

    img = cv2.imread(filename)
    print(f"Image size: {img.shape[1]}x{img.shape[0]} pixels")
    return filename

# Download a few images of different sizes
small_img = download_image("https://raw.githubusercontent.com/opencv/opencv/master/samples/data/lena.jpg", "small.jpg")
medium_img = download_image("https://images.pexels.com/photos/7189447/pexels-photo-7189447.jpeg", "medium.jpg")
large_img = download_image("https://images.pexels.com/photos/1054666/pexels-photo-1054666.jpeg?auto=compress&cs=tinysrgb&w=1260&h=750&dpr=2", "large.jpg")

"""## 3. Implementation of Grayscale Conversion Methods

Let's implement three methods for comparison:
1. CPU using Python loops (slowest, for baseline)
2. CPU using optimized OpenCV function
3. GPU using CUDA
"""

def grayscale_python_loop(img):
    """Convert to grayscale using pure Python loops (very slow, for baseline comparison)"""
    start = time.time()

    height, width, _ = img.shape
    gray = np.zeros((height, width), dtype=np.uint8)

    for y in range(height):
        for x in range(width):
            # OpenCV uses BGR order
            b, g, r = img[y, x]
            # Standard grayscale conversion formula
            gray[y, x] = int(0.114 * r + 0.587 * g + 0.299 * b)

    time_ms = (time.time() - start) * 1000
    return gray, time_ms

def grayscale_numpy(img):
    """Convert to grayscale using NumPy (vectorized, faster than loops)"""
    start = time.time()

    # OpenCV uses BGR order
    gray = (0.114 * img[:,:,2] + 0.587 * img[:,:,1] + 0.299 * img[:,:,0]).astype(np.uint8)

    time_ms = (time.time() - start) * 1000
    return gray, time_ms

def grayscale_opencv(img):
    """Convert to grayscale using OpenCV's optimized function"""
    start = time.time()

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    time_ms = (time.time() - start) * 1000
    return gray, time_ms

@cuda.jit
def grayscale_cuda_kernel(img, gray):
    x, y = cuda.grid(2)
    if x < gray.shape[1] and y < gray.shape[0]:
        b = float(img[y, x, 0])
        g = float(img[y, x, 1])
        r = float(img[y, x, 2])
        gray[y, x] = int(0.114 * r + 0.587 * g + 0.299 * b)

# Define your grayscale conversion function
def grayscale_cuda(img):
    start = time.time()
    height, width, _ = img.shape
    gray_cpu = np.empty((height, width), dtype=np.uint8)
    d_img = cuda.to_device(img)
    d_gray = cuda.to_device(gray_cpu)
    threads_per_block = (16, 16)
    blocks_x = (width + threads_per_block[0] - 1) // threads_per_block[0]
    blocks_y = (height + threads_per_block[1] - 1) // threads_per_block[1]
    blocks_per_grid = (blocks_x, blocks_y)
    grayscale_cuda_kernel[blocks_per_grid, threads_per_block](d_img, d_gray)
    d_gray.copy_to_host(gray_cpu)
    time_ms = (time.time() - start) * 1000
    return gray_cpu, time_ms

"""## 4. Performance Testing"""

def run_benchmark(img_path, iterations=3):
    """Run and compare all methods on an image"""
    img = cv2.imread(img_path)
    if img is None:
        print(f"Error: Could not load image at {img_path}")
        return

    height, width, channels = img.shape
    print(f"\nBenchmarking image: {img_path} - {width}x{height} pixels")

    # Dictionary to store results for each method
    times = {
        "Python Loops": [],
        "NumPy": [],
        "OpenCV": [],
        "CUDA": []
    }

    print("Running benchmarks...")

    # Skip Python loops for very large images
    skip_loops = width * height > 1000000  # Skip for images larger than ~1 megapixel

    # Warm-up run for CUDA
    if cuda.is_available():
        _, _ = grayscale_cuda(img)

    for i in range(iterations):
        # Run Python loops method (only for small images)
        if not skip_loops:
            _, time_python = grayscale_python_loop(img)
            times["Python Loops"].append(time_python)

        # Run NumPy method
        _, time_numpy = grayscale_numpy(img)
        times["NumPy"].append(time_numpy)

        # Run OpenCV method
        _, time_opencv = grayscale_opencv(img)
        times["OpenCV"].append(time_opencv)

        # Run CUDA method if available
        if cuda.is_available():
            _, time_cuda = grayscale_cuda(img)
            times["CUDA"].append(time_cuda)

    # Calculate average times
    avg_times = {}
    for method, method_times in times.items():
        if method_times:  # If we collected times for this method
            avg_times[method] = sum(method_times) / len(method_times)

    # Baseline (slowest) for speedup calculation
    if skip_loops:
        baseline = avg_times["NumPy"]
        print("Python loops skipped for large image")
    else:
        baseline = avg_times["Python Loops"]

    # Print results
    print("\nAverage execution times:")
    for method, avg_time in avg_times.items():
        speedup = baseline / avg_time if avg_time > 0 else 0
        print(f"{method:12s}: {avg_time:.3f} ms (Speedup: {speedup:.2f}x)")

    # Plot for visual comparison
    methods = list(avg_times.keys())
    times_list = [avg_times[m] for m in methods]

    plt.figure(figsize=(10, 6))
    bars = plt.bar(methods, times_list)
    plt.title(f"Grayscale Conversion Performance ({width}x{height} pixels)")
    plt.ylabel("Time (ms)")
    plt.yscale("log")  # Log scale to handle large time differences

    # Add time values on top of bars
    for bar, time_val in zip(bars, times_list):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() * 1.01,
                f"{time_val:.1f} ms", ha="center", va="bottom", rotation=0)

    plt.tight_layout()
    plt.show()

    # Return the results for further analysis if needed
    return {
        "image": img_path,
        "dimensions": (width, height),
        "times": avg_times
    }

"""## 5. Run Benchmarks on Different Image Sizes"""

# Run small image benchmark
small_results = run_benchmark(small_img, iterations=5)

# Run medium image benchmark
medium_results = run_benchmark(medium_img, iterations=5)

# Run large image benchmark
large_results = run_benchmark(large_img, iterations=3)

"""## 6. Summary and Visualization

Let's compare the performance across different image sizes and methods.
"""

def visualize_results(small_img, medium_img, large_img):
    # Let's demonstrate the visual result of the conversion
    small = cv2.imread(small_img)

    # Get grayscale versions
    gray_opencv, _ = grayscale_opencv(small)

    if cuda.is_available():
        gray_cuda, _ = grayscale_cuda(small)

        # Compare results
        diff = np.abs(gray_opencv.astype(np.int32) - gray_cuda.astype(np.int32))
        max_diff = np.max(diff)
        print(f"Maximum difference between OpenCV and CUDA outputs: {max_diff}")

    # Display images
    plt.figure(figsize=(15, 5))

    plt.subplot(1, 3, 1)
    plt.imshow(cv2.cvtColor(small, cv2.COLOR_BGR2RGB))
    plt.title("Original Image")
    plt.axis('off')

    plt.subplot(1, 3, 2)
    plt.imshow(gray_opencv, cmap='gray')
    plt.title("Grayscale (OpenCV)")
    plt.axis('off')

    if cuda.is_available():
        plt.subplot(1, 3, 3)
        plt.imshow(gray_cuda, cmap='gray')
        plt.title("Grayscale (CUDA)")
        plt.axis('off')

    plt.tight_layout()
    plt.show()

visualize_results(small_img, medium_img, large_img)

"""## 7. Performance Analysis

Let's analyze the speedup offered by GPU processing compared to various CPU methods across different image sizes.
"""

# Summary visualization across image sizes
if 'small_results' in locals() and 'medium_results' in locals() and 'large_results' in locals():
    # Extract dimensions and methods
    image_names = ['Small', 'Medium', 'Large']
    dimensions = [
        f"{small_results['dimensions'][0]}x{small_results['dimensions'][1]}",
        f"{medium_results['dimensions'][0]}x{medium_results['dimensions'][1]}",
        f"{large_results['dimensions'][0]}x{large_results['dimensions'][1]}"
    ]

    # Create a consistent set of methods
    all_methods = set()
    for result in [small_results, medium_results, large_results]:
        all_methods.update(result['times'].keys())
    all_methods = sorted(list(all_methods))

    # Prepare data for plotting
    data = []
    for result in [small_results, medium_results, large_results]:
        row = []
        for method in all_methods:
            if method in result['times']:
                row.append(result['times'][method])
            else:
                row.append(None)
        data.append(row)

    # Prepare the plot
    plt.figure(figsize=(12, 8))
    width = 0.2
    x = np.arange(len(image_names))

    bars = []
    for i, method in enumerate(all_methods):
        method_data = [d[i] if i < len(d) and d[i] is not None else 0 for d in data]
        bar = plt.bar(x + i*width - (len(all_methods)-1)*width/2, method_data, width, label=method)
        bars.append(bar)

    plt.title('Grayscale Conversion Performance Across Image Sizes')
    plt.xlabel('Image Size')
    plt.ylabel('Time (ms) - Log Scale')
    plt.yscale('log')  # Use log scale for better visibility
    plt.xticks(x, [f"{name}\n{dim}" for name, dim in zip(image_names, dimensions)])
    plt.legend()
    plt.grid(axis='y', linestyle='--', alpha=0.7)

    # Add value labels on bars
    for i, bar_group in enumerate(bars):
        for j, bar in enumerate(bar_group):
            height = bar.get_height()
            if height > 0:  # Only add label if there's actual data
                plt.text(bar.get_x() + bar.get_width()/2., height*1.05,
                        f'{height:.1f}', ha='center', va='bottom', rotation=90)

    plt.tight_layout()
    plt.show()

    # Calculate and display GPU vs CPU speedup
    if 'CUDA' in all_methods:
        cuda_index = all_methods.index('CUDA')
        opencv_index = all_methods.index('OpenCV')

        print("\nGPU (CUDA) vs CPU (OpenCV) Speedup:")
        for i, size in enumerate(image_names):
            cuda_time = data[i][cuda_index]
            opencv_time = data[i][opencv_index]
            if cuda_time and opencv_time:  # Make sure both values exist
                speedup = opencv_time / cuda_time
                print(f"{size} image: {speedup:.2f}x faster")

        # If we have Python loops results
        if 'Python Loops' in all_methods:
            loops_index = all_methods.index('Python Loops')
            print("\nGPU (CUDA) vs Python Loops Speedup:")
            for i, size in enumerate(image_names):
                if i < len(data) and cuda_index < len(data[i]) and loops_index < len(data[i]):
                    cuda_time = data[i][cuda_index]
                    loops_time = data[i][loops_index]
                    if cuda_time and loops_time:  # Make sure both values exist
                        speedup = loops_time / cuda_time
                        print(f"{size} image: {speedup:.2f}x faster")
else:
    print("Run all benchmarks first to see the summary!")

"""## 8. Conclusion

This notebook clearly demonstrates the performance advantages of GPU acceleration using CUDA for image processing tasks. Key takeaways:

1. **GPU Performance Scales Better**: As image size increases, the GPU advantage becomes more significant.

2. **Speedup Factors**:
   - CUDA vs Pure Python: 100x-1000x+ speedup
   - CUDA vs NumPy/OpenCV: 2x-10x speedup (depending on image size)

3. **Best Applications for GPU**:
   - Large image processing
   - Batch processing of multiple images
   - Real-time video processing
   - Complex image transformations

4. **Startup Overhead**: For very small images, the overhead of transferring data to/from the GPU can offset gains, but for realistic workloads, GPU processing is clearly superior.

With CUDA, image processing tasks that previously took seconds can now be completed in milliseconds, opening up possibilities for more complex real-time applications.
"""